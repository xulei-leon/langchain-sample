{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Deepseek LLM Grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Literal, Annotated, Optional, Union\n",
    "from typing_extensions import TypedDict\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableSerializable\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver, InMemorySaver\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# key\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "silicon_api_key = os.getenv(\"SILICON_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# deepseek\n",
    "deepseek_llm_model = \"deepseek-chat\"\n",
    "\n",
    "# silicon\n",
    "silicon_base_url =  \"https://api.siliconflow.cn/v1\"\n",
    "silicon_llm_model = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# huggingface\n",
    "huggingface_embed_model = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init LLM mod\n",
    "llm_deepseek = ChatDeepSeek(\n",
    "    model=deepseek_llm_model,\n",
    "    temperature=0.3,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    top_p=0.9,\n",
    "    frequency_penalty=0.7,\n",
    "    presence_penalty=0.5,\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "###  Grader\n",
    "################################################################################\n",
    "class Grader:\n",
    "    \"\"\"\n",
    "    Grader.\n",
    "    The score to assess relevance or answer addresses question.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: RunnableSerializable,\n",
    "        grader_type: Literal[\"relevance\", \"answer\"],\n",
    "    ):\n",
    "        self.grader_type = grader_type\n",
    "        self.schema = self._default_schema()\n",
    "        self.system_prompt = self._default_system_prompt()\n",
    "        self.chain = self._build_chain(llm)\n",
    "\n",
    "    @staticmethod\n",
    "    def _default_schema():\n",
    "        score_min = 0\n",
    "        score_max = 10\n",
    "        class GradeSchema(BaseModel):\n",
    "            score: int = Field(\n",
    "                default=0,\n",
    "                description=(\n",
    "                    \"\"\"\n",
    "                    \\rScore between 0-10\n",
    "                    \"\"\"\n",
    "                ),\n",
    "                examples=[3, 7, 9],\n",
    "                ge=score_min,\n",
    "                le=score_max\n",
    "            )\n",
    "            \n",
    "            def cast_to_int(cls, value):\n",
    "                return int(float(value))\n",
    "\n",
    "            def validate_range(cls, value):\n",
    "                if value < score_min:\n",
    "                    value = score_min\n",
    "                elif value > score_max:\n",
    "                    value = score_max;\n",
    "                    \n",
    "                return value\n",
    "\n",
    "        return GradeSchema\n",
    "    \n",
    "    #@staticmethod\n",
    "    def _default_system_prompt(self):\n",
    "        instructs = {\n",
    "            \"relevance\": \"relevance of the document to the question\",\n",
    "            \"answer\": \"answer addresses the question\",\n",
    "        }\n",
    "        instruct = instructs[self.grader_type]\n",
    "        \n",
    "        role = f\"\"\"\n",
    "            \\rRole: Scoring Expert\n",
    "            \\rTask: {instruct}\n",
    "            \\r\n",
    "            \\rGuidelines:\n",
    "            \\rYou are a professional scoring expert. Please assess the {instruct} based on the following criteria:\n",
    "            \\rScoring Criteria:\n",
    "            \\r0: Irrelevant/no answer\n",
    "            \\r3: Only keywords/no relevance\n",
    "            \\r5: Relevant keywords, partial answer\n",
    "            \\r7: Mostly relevant, insufficient support\n",
    "            \\r9: Highly relevant, detailed evidence\n",
    "            \\r10: Perfect solution/answer\n",
    "        \"\"\"\n",
    "\n",
    "        respond_request = \"\"\"\n",
    "            \\rEvaluation Criteria: Keyword Match, Relevance, Evidence Strength\n",
    "            \\rCurrent Scenario: Rapid Response Mode\n",
    "        \"\"\"\n",
    "\n",
    "        response_format = \"\"\"\n",
    "            \\rPlease return a number score from 0-10.\n",
    "            \\rNo explanations or additional text.\n",
    "        \"\"\"\n",
    "    \n",
    "        return f\"{role}\\n{respond_request}\\n{response_format}\"\n",
    "    \n",
    "    def _build_chain(self, llm: RunnableSerializable) -> RunnableSerializable:\n",
    "        structured_llm = llm.with_structured_output(self.schema)\n",
    "\n",
    "        instructs = {\n",
    "            \"relevance\": \"Rrelevance document\",\n",
    "            \"answer\": \"Aanswer\",\n",
    "        }\n",
    "        instruct = instructs[self.grader_type]\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.system_prompt),\n",
    "            (\"human\", f\"{instruct}: \\n\\n {{document}} \\n\\n Question: {{question}}\")\n",
    "        ])\n",
    "        \n",
    "        return prompt_template | structured_llm\n",
    "    \n",
    "    def invoke(\n",
    "        self,\n",
    "        document: str,\n",
    "        question: str,\n",
    "        **kwargs\n",
    "    ) -> Union[str, dict]:\n",
    "        inputs = {\n",
    "            \"document\": document,\n",
    "            \"question\": question,\n",
    "            **kwargs\n",
    "        }\n",
    "        return self.chain.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test relevance grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_grader = Grader(llm=llm_deepseek, grader_type=\"relevance\")\n",
    "print(\"=== relevance grader system_prompt ===\")\n",
    "print(relevance_grader.system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Test Grade: yes\n",
    "##\n",
    "\n",
    "user_input = \"What are the ingredients in Alpha Hope?\"\n",
    "retrieval_document = \"\"\"\n",
    "Alpha Hope has been formulated with two powerful active ingredients, PQQ and Molecular Hydrogen.\n",
    "They work synergistically to activate metabolic pathways involved in energy production and cognition.\n",
    "This is particularly formulated to promote the bodyâ\\x80\\x99s natural detox process and help the body naturally produce Hope Molecules,\\\n",
    "also known as PGC-1Î±, that fight oxidative damage.\n",
    "\"\"\"\n",
    "grade = relevance_grader.invoke(question=user_input, document=retrieval_document)\n",
    "print(f\"relevance grade is {grade.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test answer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_grader = Grader(llm=llm_deepseek, grader_type=\"answer\")\n",
    "print(\"=== answer grader system_prompt ===\")\n",
    "print(answer_grader.system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Test Grade: no\n",
    "##\n",
    "\n",
    "user_input = \"What are the ingredients in Alpha Hope?\"\n",
    "retrieval_document = \"\"\"\n",
    "Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.\n",
    "It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
    "\"\"\"\n",
    "\n",
    "grade = answer_grader.invoke(question=user_input, document=retrieval_document)\n",
    "print(f\"answer grade is {grade.score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
