{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "LLM prompt for grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Literal, Annotated, Optional, Union\n",
    "from typing_extensions import TypedDict\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.runnables import RunnableSerializable\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver, InMemorySaver\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# key\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "silicon_api_key = os.getenv(\"SILICON_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# deepseek\n",
    "deepseek_llm_model = \"deepseek-chat\"\n",
    "\n",
    "# silicon\n",
    "silicon_base_url =  \"https://api.siliconflow.cn/v1\"\n",
    "silicon_llm_model = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# huggingface\n",
    "huggingface_embed_model = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init LLM mod\n",
    "llm_deepseek = ChatDeepSeek(\n",
    "    model=deepseek_llm_model,\n",
    "    temperature=0.3,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    top_p=0.9,\n",
    "    frequency_penalty=0.7,\n",
    "    presence_penalty=0.5,\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepseek Relevance Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "###  Document Relevance Grader\n",
    "################################################################################\n",
    "class DocumentRelevanceGrader:\n",
    "    \"\"\"\n",
    "    Document Relevance Grader.\n",
    "    Binary score for relevance check on retrieved documents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: RunnableSerializable,\n",
    "        system_prompt: Optional[str] = None,\n",
    "        grade_schema: Optional[BaseModel] = None\n",
    "    ):\n",
    "        self.grade_schema = grade_schema or self._default_grade_schema()\n",
    "        self.system_prompt = system_prompt or self._default_system_prompt()\n",
    "        self.chain = self._build_chain(llm)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _default_grade_schema():\n",
    "        score_min = 0\n",
    "        score_max = 10\n",
    "        class GradeSchema(BaseModel):\n",
    "            relevance_score: int = Field(\n",
    "                default=0,\n",
    "                description=(\n",
    "                    \"\"\"\n",
    "                    \\rThe relevance of the document to the question, score between 0-10\n",
    "                    \"\"\"\n",
    "                ),\n",
    "                examples=[3, 7, 9],\n",
    "                ge=score_min,\n",
    "                le=score_max\n",
    "            )\n",
    "            \n",
    "            @validator('relevance_score', pre=True)\n",
    "            def cast_to_int(cls, value):\n",
    "                return int(float(value))\n",
    "\n",
    "            @validator('relevance_score')\n",
    "            def validate_range(cls, value):\n",
    "                if value < score_min:\n",
    "                    value = score_min\n",
    "                elif value > score_max:\n",
    "                    value = score_max;\n",
    "                    \n",
    "                return value\n",
    "\n",
    "        return GradeSchema\n",
    "    \n",
    "    @staticmethod\n",
    "    def _default_system_prompt():\n",
    "        role = \"\"\"\n",
    "            \\rRole: Document Relevance Scoring Expert\n",
    "            \\rTask: Assess the relevance of the document to the question\n",
    "            \\r\n",
    "            \\rGuidelines:\n",
    "            \\rYou are a professional document relevance scoring expert. Please assess the relevance of the document to the question based on the following criteria:\n",
    "            \\rScoring Criteria:\n",
    "            \\r0 points - Document content is completely irrelevant to the question\n",
    "            \\r3 points - Contains only individual keywords but no real relevance\n",
    "            \\r5 points - Contains relevant keywords but lacks semantic relevance\n",
    "            \\r7 points - Largely relevant but insufficient supporting evidence\n",
    "            \\r9 points - Highly relevant with detailed evidence\n",
    "            \\r10 points - Perfectly matches the problem and provides a complete solution\n",
    "        \"\"\"\n",
    "\n",
    "        respond_request = \"\"\"\n",
    "            \\rRespond to the request:\n",
    "            \\r1. degree of keyword match\n",
    "            \\r2. semantic relevance\n",
    "            \\r3. strength of evidential support\n",
    "            \\r\n",
    "            \\rCurrent Scenario: Rapid Response Mode\n",
    "        \"\"\"\n",
    "\n",
    "        response_format = \"\"\"\n",
    "            \\rPlease return a whole number score from 0-10.\n",
    "            \\rNo explanations or additional text.\n",
    "        \"\"\"\n",
    "    \n",
    "        return f\"{role}\\n{respond_request}\\n{response_format}\"\n",
    "    \n",
    "    def _build_chain(self, llm: RunnableSerializable) -> RunnableSerializable:\n",
    "        structured_llm = llm.with_structured_output(self.grade_schema)\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.system_prompt),\n",
    "            (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\")\n",
    "        ])\n",
    "        \n",
    "        return prompt_template | structured_llm\n",
    "    \n",
    "    def grade(\n",
    "        self,\n",
    "        document: str,\n",
    "        question: str,\n",
    "        **kwargs\n",
    "    ) -> Union[str, dict]:\n",
    "        inputs = {\n",
    "            \"document\": document,\n",
    "            \"question\": question,\n",
    "            **kwargs\n",
    "        }\n",
    "        return self.chain.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = DocumentRelevanceGrader(llm=llm_deepseek)\n",
    "print(f\"system_prompt is {grader.system_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Test Grade: yes\n",
    "##\n",
    "\n",
    "user_input = \"What are the ingredients in Alpha Hope?\"\n",
    "retrieval_document = \"\"\"\n",
    "Alpha Hope has been formulated with two powerful active ingredients, PQQ and Molecular Hydrogen.\n",
    "They work synergistically to activate metabolic pathways involved in energy production and cognition.\n",
    "This is particularly formulated to promote the bodyâ\\x80\\x99s natural detox process and help the body naturally produce Hope Molecules,\\\n",
    "also known as PGC-1Î±, that fight oxidative damage.\n",
    "\"\"\"\n",
    "grade = grader.grade(question=user_input, document=retrieval_document)\n",
    "print(f\"grade is {grade.relevance_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Test Grade: no\n",
    "##\n",
    "\n",
    "user_input = \"What are the ingredients in Alpha Hope?\"\n",
    "retrieval_document = \"\"\"\n",
    "Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.\n",
    "It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
    "\"\"\"\n",
    "\n",
    "grade = grader.grade(question=user_input, document=retrieval_document)\n",
    "print(f\"grade is {grade.relevance_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
